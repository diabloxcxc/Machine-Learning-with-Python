{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2_train_file = 'C:/Users/chandlerxing/Desktop/Financial Analytics\train1.csv'\n",
    "df = pd.read_csv(path_2_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'id', 'visitTime', 'purchaseTime', 'hour', 'C1', 'C2', 'C3',\n",
       "       'C4', 'C5', 'C6', 'C7', 'C8', 'N1', 'C9', 'N2', 'N3', 'N4', 'N5', 'N6',\n",
       "       'N7', 'N8', 'N9', 'N10', 'C10', 'C11', 'C12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2569487005    8430\n",
       "2108523568       7\n",
       "2084406919       6\n",
       "3438432991       5\n",
       "256353298        5\n",
       "              ... \n",
       "1427705163       1\n",
       "4180196685       1\n",
       "596547023        1\n",
       "3559230936       1\n",
       "77004800         1\n",
       "Name: C1, Length: 22595, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['C1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928325921    1232\n",
       "3475347077    1212\n",
       "2780744710    1179\n",
       "1711803242     936\n",
       "1822656032     536\n",
       "              ... \n",
       "3540895230       1\n",
       "2756181513       1\n",
       "3550862535       1\n",
       "1199484467       1\n",
       "1533319149       1\n",
       "Name: C3, Length: 2863, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['C3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3469607743    1425\n",
       "3458698981      82\n",
       "3183725626      73\n",
       "1133005353      71\n",
       "3662869197      68\n",
       "              ... \n",
       "843115400        1\n",
       "762569609        1\n",
       "4142922634       1\n",
       "830608273        1\n",
       "487200771        1\n",
       "Name: C10, Length: 28653, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['C10'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = df['label'].values\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[         0, 1830830742,  652481754, ...,          0, 3617851689,\n",
       "        4220791646],\n",
       "       [         0,  403381353,  652481754, ...,          0, 3831440054,\n",
       "        1213938795],\n",
       "       [         0,  403381353,  652481754, ...,          0, 2379633508,\n",
       "        1284343215],\n",
       "       ...,\n",
       "       [        23, 1235983246,  652481754, ...,          0,  621902171,\n",
       "        3706004275],\n",
       "       [        23,  403381353,  652481754, ...,          0, 3617851689,\n",
       "        4220791646],\n",
       "       [        23,  403381353,  652481754, ...,          0, 3617851689,\n",
       "        4220791646]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(columns=['label','id','visitTime','purchaseTime','C1','C3','C10']).values\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.copy()\n",
    "y = np.array(label.copy())\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "y = (y > 0)*1\n",
    "nb_class = len(set(y))\n",
    "print(nb_class) \n",
    "id_Train = np.array([None]*nb_class)\n",
    "id_Test = np.array([None]*nb_class)\n",
    "for i in range(nb_class):\n",
    "    id_i = np.where(y==i)[0]\n",
    "    id_i_train, id_i_test = train_test_split(id_i, test_size=0.3, random_state=123,shuffle=True)\n",
    "    id_Train[i] = id_i_train\n",
    "    id_Test[i] = id_i_test\n",
    "\n",
    "id_Train = np.concatenate(id_Train)\n",
    "id_Test = np.concatenate(id_Test)\n",
    "\n",
    "X_train = X[id_Train]\n",
    "Y_train = y[id_Train]\n",
    "X_test = X[id_Test]\n",
    "Y_test = y[id_Test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([         9, 1830830742,  306394936, 2967512603, 2712499304,\n",
       "       2303407174, 1804593680,          0,  385980380,          0,\n",
       "                0,          0,          0,          0,          0,\n",
       "                0,          0,          0,  621902171,  830706566])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10261, 17599, 25347, ..., 18397,  2470, 24118])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before resampling\n",
      "[21959, 39]\n",
      "after resampling\n",
      "[474, 94]\n"
     ]
    }
   ],
   "source": [
    "id_toTrain = np.array([np.where(Y_train==i)[0] for i in range(nb_class)])\n",
    "\n",
    "size_max = [len(id_toTrain[i]) for i in range(nb_class)]\n",
    "print(\"before resampling\")\n",
    "print(size_max)\n",
    "\n",
    "blc = 150\n",
    "for i in range(len(size_max)):\n",
    "    if size_max[i] > blc:\n",
    "        size_max[i] = int(blc*(np.log10(size_max[i]/blc)+1))\n",
    "    else:\n",
    "        size_max[i] = int(blc/(np.log10(blc/size_max[i])+1))\n",
    "\n",
    "print(\"after resampling\")\n",
    "print(size_max)\n",
    "for i in range(nb_class):\n",
    "    if len(id_toTrain[i]) > size_max[i]:\n",
    "        id_toTrain[i], tmp = train_test_split(id_toTrain[i], test_size=1-size_max[i]/len(id_toTrain[i]))\n",
    "    else:\n",
    "        id_toTrain[i] = np.concatenate((id_toTrain[i], id_toTrain[i][np.random.randint(len(id_toTrain[i]), size=int(size_max[i]-len(id_toTrain[i])))]))\n",
    "id_toTrain = np.concatenate(id_toTrain)\n",
    "X_toTrain = X_train[id_toTrain]\n",
    "Y_toTrain = Y_train[id_toTrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [

   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "0.988953541231021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     21959\n",
      "           1       0.14      1.00      0.24        39\n",
      "\n",
      "    accuracy                           0.99     21998\n",
      "   macro avg       0.57      0.99      0.62     21998\n",
      "weighted avg       1.00      0.99      0.99     21998\n",
      "\n",
      "\n",
      "\n",
      "Testing\n",
      "0.988441145281018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      9412\n",
      "           1       0.13      0.89      0.23        18\n",
      "\n",
      "    accuracy                           0.99      9430\n",
      "   macro avg       0.56      0.94      0.61      9430\n",
      "weighted avg       1.00      0.99      0.99      9430\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-8d8120354103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Print out the feature and importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Variable: {:20} Importance: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_importances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-8d8120354103>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Print out the feature and importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Variable: {:20} Importance: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_importances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import accuracy_score as acs\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "print('Training')\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "rf = RandomForestClassifier(max_depth = 15, random_state=123,max_leaf_nodes=60)\n",
    "rf = rf.fit(X_toTrain, Y_toTrain)\n",
    "train_pred = rf.predict(X_train)\n",
    "print(metrics.accuracy_score(Y_train,train_pred))\n",
    "print(metrics.classification_report(Y_train,train_pred))\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Testing')\n",
    "\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "#Evaluate predictions\n",
    "print(metrics.accuracy_score(Y_test,y_pred))\n",
    "print(metrics.classification_report(Y_test,y_pred))\n",
    "\n",
    "# Get numerical feature importances\n",
    "feature_list = X\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.002\n",
    "selector = SelectFromModel(rf, threshold=0.001)\n",
    "\n",
    "# Train the selector\n",
    "selector.fit(X_toTrain, Y_toTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the names of the most important features\n",
    "my_list = []\n",
    "\n",
    "for feature_list_index in selector.get_support(indices=True):\n",
    "    #print(X.columns[feature_list_index])\n",
    "    my_list.append(X[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0.9859154929577465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       474\n",
      "           1       0.99      0.93      0.96        94\n",
      "\n",
      "    accuracy                           0.99       568\n",
      "   macro avg       0.99      0.96      0.97       568\n",
      "weighted avg       0.99      0.99      0.99       568\n",
      "\n",
      "test\n",
      "0.9937433722163309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      9412\n",
      "           1       0.22      0.89      0.35        18\n",
      "\n",
      "    accuracy                           0.99      9430\n",
      "   macro avg       0.61      0.94      0.67      9430\n",
      "weighted avg       1.00      0.99      1.00      9430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_important_train = selector.transform(X_toTrain)\n",
    "X_important_test = selector.transform(X_test)\n",
    "\n",
    "# New Random Forest model.\n",
    "clf_important = RandomForestClassifier(max_depth = 12, random_state=123, n_estimators = 500 ,max_leaf_nodes = 15)\n",
    "\n",
    "# Train the new classifier.\n",
    "clf_important.fit(X_important_train, Y_toTrain)\n",
    "y_important_pred = clf_important.predict(X_important_train)\n",
    "print('train')\n",
    "print(metrics.accuracy_score(Y_toTrain,y_important_pred))\n",
    "\n",
    "print(metrics.classification_report(Y_toTrain,y_important_pred))\n",
    "print('test')\n",
    "y_important_test_pred = clf_important.predict(X_important_test)\n",
    "print(metrics.accuracy_score(Y_test,y_important_test_pred))\n",
    "print(metrics.classification_report(Y_test,y_important_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
  
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "Rfmodel = 'C:/Users/chandlerxing/Desktop/Financial Analytics/model_trained.sav'\n",
    "pickle.dump(clf_important, open(Rfmodel, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model.\n",
    "loaded_model = pickle.load(open(Rfmodel, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv(\"C:/Users/chandlerxing/Desktop/Financial Analytics/test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelt = dft['label'].values\n",
    "labelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[         0,  403381353,  652481754, ...,          0,          0,\n",
       "        4220791646],\n",
       "       [         0, 1235983246,  652481754, ...,          0,          0,\n",
       "        1284343215],\n",
       "       [         0, 1235983246,  652481754, ...,          0,          0,\n",
       "        1213938795],\n",
       "       ...,\n",
       "       [        23,  403381353,  652481754, ...,          0,          0,\n",
       "        4220791646],\n",
       "       [        23, 2541203883, 2308170622, ...,          0,          0,\n",
       "        4220791646],\n",
       "       [        23,  403381353,  652481754, ...,          0,          0,\n",
       "        4220791646]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datat = dft.drop(columns=['label','id','visitTime','purchaseTime','C1','C3','C10','C11']).values\n",
    "datat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['prob0'] = loaded_model.predict_proba(datat)[0:,0]\n",
    "dft = dft[['id','prob0']]\n",
    "dft.to_csv('C:/Users/chandlerxing/Desktop/Financial Analytics/Predict.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
